{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "import aesara.tensor as aet\n",
    "import pandas as pd\n",
    "import pycmtensor as cmt\n",
    "from pycmtensor.pycmtensor import PyCMTensorModel, Beta, Weights\n",
    "from pycmtensor.functions import logit, neg_loglikelihood\n",
    "from pycmtensor.optimizers import Adam\n",
    "from pycmtensor.results import Results\n",
    "\n",
    "swissmetro = pd.read_csv(\"data/swissmetro.dat\", sep=\"\\t\")\n",
    "db = cmt.Database(\"swissmetro\", swissmetro, choiceVar=\"CHOICE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some observations\n",
    "exclude = ((db.variables[\"PURPOSE\"] != 1) * (db.variables[\"PURPOSE\"] != 3) + (db.variables[\"CHOICE\"] == 0)) > 0\n",
    "db.remove(exclude)\n",
    "\n",
    "# additional steps to format database\n",
    "db.data[\"CHOICE\"] -= 1 # set the first choice to 0\n",
    "db.autoscale(variables=['TRAIN_CO', 'TRAIN_TT', 'CAR_CO', 'CAR_TT', \n",
    "    'SM_CO', 'SM_TT'], default=100., verbose=False)\n",
    "\n",
    "\n",
    "class ResLogitLayer:\n",
    "    def __init__(self, input, w_in, w_out):\n",
    "        if isinstance(input, (list, tuple)):\n",
    "            input = aet.concatenate(input, axis=1)\n",
    "        \n",
    "        # assert len(input) == w_in.shape[0], f\"{input} must have the same length as the in first dimension of {w_in}.\"\n",
    "        # assert w_in.shape[-1] == w_out.shape[0], f\"Out dimension of {w_in} must have the same length as the in dimension of {w_out}.\"\n",
    "        if isinstance(w_in, (Weights)):\n",
    "            w_in = w_in()\n",
    "        if isinstance(w_out, (Weights)):\n",
    "            w_out = w_out()\n",
    "            \n",
    "        h = aet.sigmoid(aet.dot(input, w_in))\n",
    "        output = aet.sigmoid(aet.dot(h, w_out))\n",
    "        self.input = input\n",
    "        self.weights = [w_in, w_out]\n",
    "        self.output = output + input\n",
    "\n",
    "\n",
    "class MNLmodel(PyCMTensorModel):\n",
    "    def __init__(self, db):\n",
    "        super().__init__()\n",
    "        self.name = \"myModel\"\n",
    "        self.inputs = db.inputs()  # keep track of inputs\n",
    "\n",
    "        # update global variables from database\n",
    "        for var in self.inputs:\n",
    "            globals().update({var.name: var})\n",
    "\n",
    "        # declare model params here\n",
    "        b_cost = Beta(\"b_cost\", 0.0, None, None, 0)\n",
    "        b_time = Beta(\"b_time\", 0.0, None, None, 0)\n",
    "        asc_train = Beta(\"asc_train\", 0.0, None, None, 0)\n",
    "        asc_car = Beta(\"asc_car\", 0.0, None, None, 0)\n",
    "        asc_sm = Beta(\"asc_sm\", 0.0, None, None, 1)\n",
    "\n",
    "        W1 = Weights(\"ResNet_01a\", (3, 10), 0, True)\n",
    "        W2 = Weights(\"ResNet_01b\", (10, 3), 0, True)\n",
    "\n",
    "        # pass model params to self.params\n",
    "        self.store_params(locals())\n",
    "\n",
    "        # Definition of the utility functions\n",
    "        U_1 = b_cost * TRAIN_CO + b_time * TRAIN_TT + asc_train\n",
    "        U_2 = b_cost * SM_CO + b_time * SM_TT + asc_sm\n",
    "        U_3 = b_cost * CAR_CO + b_time * CAR_TT + asc_car\n",
    "        U = [U_1, U_2, U_3]\n",
    "        rh = ResLogitLayer(U, W1, W2)\n",
    "\n",
    "        # definition of the choice output\n",
    "        self.y = CHOICE\n",
    "\n",
    "        # symbolic expression for the choice model\n",
    "        self.p_y_given_x = logit(rh.output, [TRAIN_AV, SM_AV, CAR_AV])\n",
    "\n",
    "        # declare Regularizers here:\n",
    "        # L1 regularization cost\n",
    "        self.L1 = abs(b_cost()) + abs(b_time())\n",
    "\n",
    "        # L2 regularization cost\n",
    "        self.L2 = b_cost() ** 2 + b_time() ** 2\n",
    "\n",
    "        # symbolic expression for the cost fuction\n",
    "        self.cost = neg_loglikelihood(self.p_y_given_x, self.y)\n",
    "        self.cost = self.cost\n",
    "\n",
    "        # symbolic description of how to compute prediction as class whose\n",
    "        # probability is maximal\n",
    "        self.pred = aet.argmax(self.p_y_given_x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "dataset: swissmetro (6768)\n",
      "batch size: 256\n",
      "batches per epoch: 26\n",
      "validation frequency: 26\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loglikelihood:  -5652.154684  Score: 0.611\n",
      "Epoch    4/4: 100%|██████████| 104/104 [00:03<00:00, 28.4it/s, Patience=2%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization complete with accuracy of 61.111%\n",
      " with maximum loglikelihood reached @ epoch 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model my model\n",
      "Number of Beta parameters: 4\n",
      "Total size of Neural Net weights: 60\n",
      "Sample size: 6768\n",
      "Init loglikelihood: -6969.875\n",
      "Final loglikelihood: -5652.155\n",
      "Likelihood ratio test: 2635.441\n",
      "Accuracy: 61.111%\n",
      "Rho square: 0.189\n",
      "Rho bar square: 0.180\n",
      "Akaike Information Criterion: 11432.31\n",
      "Bayesian Information Criterion: 11868.79\n",
      "Final gradient norm: 0.194\n",
      "\n",
      "              Value   Std err     t-test   p-value Rob. Std err Rob. t-test Rob. p-value\n",
      "asc_car    0.159757  0.040053   3.988602  0.000066     0.279087    0.572427     0.567033\n",
      "asc_sm          0.0         -          -         -            -           -            -\n",
      "asc_train -0.416775  0.051887  -8.032309       0.0     0.564355   -0.738499     0.460211\n",
      "b_cost     0.019433  0.003255   5.970887       0.0     0.008938    2.174134     0.029695\n",
      "b_time    -0.522085  0.044527 -11.725024       0.0     0.534529    -0.97672     0.328708 \n",
      "\n",
      "ResNet_01a (3, 10) init: random\n",
      "[[ 0.12569721 -0.07885385 -0.72176806 -0.37371185 -0.08264174  0.52840533\n",
      "  -0.55916406 -0.21908423  0.23144318 -0.94810396]\n",
      " [ 0.09591693  0.11011944 -0.00767328 -0.42669307 -0.2324131   0.55624212\n",
      "   0.1164451   0.61033787 -0.47882284 -0.35668303]\n",
      " [-0.16723925 -0.89544353 -1.09314636 -0.83100829  0.34260621 -0.45466913\n",
      "  -0.31497057  0.90542192 -0.52131117 -0.96254286]]\n",
      "\n",
      "ResNet_01b (10, 3) init: random\n",
      "[[-0.74302575 -0.18546123  0.02239637]\n",
      " [-0.10027478  0.60683775  0.20868871]\n",
      " [-0.67965451  0.58174327  0.45073315]\n",
      " [-0.28992563  0.68580635 -0.15956014]\n",
      " [-0.44581378 -0.20190104 -0.46395653]\n",
      " [ 0.21300286  0.1643613  -0.39210565]\n",
      " [-1.02170177  0.45541985 -0.15031373]\n",
      " [ 0.17214502  0.01408498 -0.08868786]\n",
      " [-0.62315217 -0.22477431  0.03138552]\n",
      " [-0.54883593  0.29214916  0.03063964]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train function\n",
    "model = cmt.train(MNLmodel, db, optimizer=Adam, batch_size=256, lr_init=0.01, max_epoch=4)\n",
    "\n",
    "with open(\"myModel.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "result = Results(model, db, show_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model my model\n",
      "Number of Beta parameters: 4\n",
      "Total size of Neural Net weights: 60\n",
      "Sample size: 6768\n",
      "Init loglikelihood: -6969.875\n",
      "Final loglikelihood: -5652.155\n",
      "Likelihood ratio test: 2635.441\n",
      "Accuracy: 61.111%\n",
      "Rho square: 0.189\n",
      "Rho bar square: 0.180\n",
      "Akaike Information Criterion: 11432.31\n",
      "Bayesian Information Criterion: 11868.79\n",
      "Final gradient norm: 0.194\n",
      "              Value   Std err     t-test   p-value Rob. Std err Rob. t-test Rob. p-value\n",
      "asc_car    0.159757  0.040053   3.988602  0.000066     0.279087    0.572427     0.567033\n",
      "asc_sm          0.0         -          -         -            -           -            -\n",
      "asc_train -0.416775  0.051887  -8.032309       0.0     0.564355   -0.738499     0.460211\n",
      "b_cost     0.019433  0.003255   5.970887       0.0     0.008938    2.174134     0.029695\n",
      "b_time    -0.522085  0.044527 -11.725024       0.0     0.534529    -0.97672     0.328708\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da63d4e9fb59fde60e5c971c6a46911019e2bb62eca7ad51842ebf786c79b6c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
